# The Unicode Standard
Unicode is a text encoding standard that maps characters to integer code points. As of Unicode 16.0 (released
in September 2024), the standard defines 154,998 characters across 168 scripts. For example, the character
“s” has the code point 115 (typically notated as U+0073, where U+ is a conventional prefix and 0073 is 115 in
hexadecimal), and the character “牛” has the code point 29275. In Python, you can use the ord() function
to convert a single Unicode character into its integer representation. The chr() function converts an integer
Unicode code point into a string with the corresponding character.

```python
>>> ord('牛')
29275
>>> chr(29275)
'牛'
```

### What Unicode character does chr(0) return?
Символ `\x00` — это **шестнадцатеричное представление нулевого байта** (ASCII-код `0`), также известного как **NUL-символ**. Это непечатаемый управляющий символ, который имеет несколько ключевых особенностей и применений.

---

#### **1. Что это такое?**
- **Escape-последовательность**: В языках программирования (Python, C, JavaScript и др.) `\x00` используется для обозначения байта со значением `0` в шестнадцатеричной системе.
- **ASCII-таблица**: Соответствует символу `NUL` (нулевой символ).

---

#### **2. Где встречается?**
##### **a. В программировании**:
- **C/C++**: Маркер конца строки в C-строках (null-terminated strings).  
  Например: Строка `"Hello"` в памяти хранится как `H e l l o \x00`.
- **Языки с управлением памятью**: Может использоваться для заполнения буферов или обозначения пустых значений.

##### **b. В данных**:
- **Бинарные файлы**: Нулевые байты часто встречаются в заголовках файлов или структурах данных.
- **Сетевые пакеты**: Могут содержать `\x00` как часть протоколов.
- **Текстовые редакторы**: Иногда отображаются как пробелы или странные символы (например, `^@` в Vim).

---

#### **3. Проблемы, связанные с `\x00`**
- **Усечение строк**: В C-подобных языках функции обработки строк (например, `strcpy`) останавливаются при встрече `\x00`, что может привести к уязвимостям (например, **buffer overflow**).
- **Некорректная обработка**:
  - В вебе (HTTP, JSON): `\x00` недопустим в URL или JSON-строках и может вызвать ошибки парсинга.
  - В базовых текстовых форматах (CSV, XML): Может нарушить структуру данных.
- **Скрытые угрозы**: Злоумышленники иногда используют `\x00` для обхода проверок (например, в путях файлов: `file.txt\x00.jpg`).

---

#### **4. Как обрабатывать `\x00`?**
- **Удаление**:  
  ```python
  text = text.replace('\x00', '')  # Python
  ```
- **Проверка на наличие**:  
  ```python
  if '\x00' in text:
      print("Обнаружен нулевой байт!")
  ```
- **Кодирование**: При работе с бинарными данными используйте Base64 или шестнадцатеричное представление.
- **Экранирование**: В некоторых контекстах (например, JSON) требуется замена на Unicode-эквивалент `\u0000`.

---

#### **5. Примеры**
##### **В Python**:
```python
s = "Hello\x00World"
print(s)  # Выведет "HelloWorld" (нулевой байт может не отображаться).
print(len(s))  # 11 (H e l l o \x00 W o r l d).
```

##### **В C**:
```c
char str[] = "Hello\x00World"; 
printf("%s", str); // Выведет "Hello", так как printf остановится на \x00.
```

---

### **6. Разница между `\x00`, `\0`, `0x00`**
- `\x00` — шестнадцатеричный escape-символ (в строковых литералах).
- `\0` — восьмеричный escape-символ для нулевого байта (тоже `0` в ASCII).
- `0x00` — шестнадцатеричное представление числа `0` (вне строк, например, в бинарных операциях).

---

#### **7. Зачем вообще нужен нулевой байт?**
- **Маркер окончания данных**: В C-строках, буферах.
- **Заполнитель**: Для выравнивания структур данных в памяти.
- **Флаги**: В некоторых протоколах обозначает пустые или неинициализированные значения.

---

#### **Заключение**
`\x00` — это технический символ, который редко встречается в обычном тексте, но критически важен в низкоуровневом программировании и бинарных данных. Если вы наткнулись на него в неожиданном месте (например, в текстовом файле), стоит проверить данные на целостность или выполнить санитарную обработку.


## How does this character’s string representation (__repr__()) differ from its printed representation?
В Python методы `__repr__()` и печатное представление (например, через `print()`) по-разному обрабатывают символы, особенно непечатаемые, такие как `\x00`. Вот ключевые отличия:

---

### **1. `__repr__()`**
- **Цель**: Возвращает **однозначное строковое представление** объекта, часто используемое для отладки.
- **Для строк**:
  - Непечатаемые символы (например, `\x00`) отображаются как **escape-последовательности**.
  - Пример:
    ```python
    s = "A\x00B"
    print(repr(s))  # Выведет: 'A\x00B'
    ```

---

### **2. Печатное представление (через `print()`)**
- **Цель**: Показать «читаемую» версию строки.
- **Для строк**:
  - Непечатаемые символы (включая `\x00`) либо **не отображаются**, либо заменяются на пробелы/спецсимволы.
  - Пример:
    ```python
    s = "A\x00B"
    print(s)  # Может вывести: 'AB' (с невидимым \x00 между A и B).
    ```

---

### **Пример кода**
```python
s = "Hello\x00World"
print(s)          # Вывод: HelloWorld (без видимого \x00)
print(repr(s))    # Вывод: 'Hello\x00World'
```

---

### **Почему так происходит?**
- `__repr__()` предназначен для точного представления объекта, включая служебные символы.
- `print()` использует `__str__()`, который оптимизирован для удобства чтения (непечатаемые символы скрыты).

---

### **Сравнение**
| **Критерий**       | **`__repr__()`**                  | **`print()`**                     |
|---------------------|-----------------------------------|-----------------------------------|
| **Непечатаемые символы** | Показывает как `\x00`, `\n` и т.д. | Скрывает или заменяет их          |
| **Цель**            | Отладка, точное представление     | Человекочитаемый вывод            |
| **Пример**          | `'A\x00B'`                        | `A B` (зависит от терминала)      |

---

### **Важно**
- В некоторых терминалах `\x00` может отображаться как **пробел** или **спецсимвол** (например, `^@`), но это зависит от настроек среды.
- Если вы работаете с бинарными данными, всегда используйте `repr()`, чтобы увидеть служебные символы.


## 2.2 Unicode Encodings

**UTF-8** и **UTF-16** — это способы кодирования символов стандарта **Unicode** в байты. Unicode нужен, чтобы каждому символу из любого языка (даже эмодзи 😊) присвоить уникальный номер (например, `A` → `U+0041`, `Я` → `U+042F`). Но чтобы сохранить или передать текст, эти номера нужно превратить в байты — для этого и существуют UTF-8 и UTF-16.

```python
>>> test_string = "hello! こんにちは!"
>>> utf8_encoded = test_string.encode("utf-8")
>>> print(utf8_encoded)
b'hello! \xe3\x81\x93\xe3\x82\x93\xe3\x81\xab\xe3\x81\xa1\xe3\x81\xaf!'
>>> print(type(utf8_encoded))
<class 'bytes'>
>>> # Get the byte values for the encoded string (integers from 0 to 255).
>>> list(utf8_encoded)
[104, 101, 108, 108, 111, 33, 32, 227, 129, 147, 227, 130, 147, 227, 129, 171, 227, 129,
161, 227, 129, 175, 33]
>>> # One byte does not necessarily correspond to one Unicode character!
>>> print(len(test_string))
13
>>> print(len(utf8_encoded))
23
>>> print(utf8_encoded.decode("utf-8"))
hello! こんにちは!
```
---

### **Что такое UTF-8?**
- **Переменная длина**: Символы кодируются **от 1 до 4 байтов**.
  - Латинские буквы (A-Z, a-z) → **1 байт** (как в старом ASCII).
  - Кириллица, греческие символы → **2 байта**.
  - Иероглифы, эмодзи → **3-4 байта**.
- **Совместимость с ASCII**: Файлы, написанные в ASCII, автоматически валидны в UTF-8.
- **Пример**: Слово `Hello` → `48 65 6C 6C 6F` (5 байтов), `Привет` → `D0 9F D1 80 D0 B8 D0 B2 D0 B5 D1 82` (12 байтов).

---

### **Что такое UTF-16?**
- **Фиксированная или переменная длина**: 
  - Большинство символов → **2 байта** (например, `A` → `0041`, `Я` → `042F`).
  - Редкие символы (эмодзи, древние языки) → **4 байта** (используются **суррогатные пары**).
- **Порядок байтов**: Важен порядок байтов (**BOM**, Byte Order Mark: `FEFF` или `FFFE`), что может усложнять обработку.
- **Пример**: `Hello` → `00 48 00 65 00 6C 00 6C 00 6F` (10 байтов), `Привет` → `04 1F 04 40 04 38 04 32 04 35 04 42` (12 байтов).

---

### **Разница между UTF-8 и UTF-16**
| **Критерий**         | **UTF-8**                          | **UTF-16**                        |
|-----------------------|------------------------------------|-----------------------------------|
| **Размер символа**    | 1–4 байта (гибко)                 | 2 или 4 байта (чаще 2)            |
| **Эффективность**     | Лучше для латиницы и смешанных текстов | Лучше для азиатских языков (китайский, японский) |
| **Совместимость**     | Полная совместимость с ASCII       | Нет совместимости с ASCII         |
| **BOM (маркер порядка байтов)** | Не требуется                 | Часто требуется (`FEFF` или `FFFE`) |
| **Использование**     | Веб, Linux, macOS, современные API | Windows, Java, старые системы     |
| **Пример для "A"**    | `41` (1 байт)                     | `0041` (2 байта)                 |
| **Пример для "Я"**    | `D0 AF` (2 байта)                 | `042F` (2 байта)                 |
| **Пример для "😊"**   | `F0 9F 98 8A` (4 байта)           | `D83D DE0A` (4 байта)            |

---

### **Почему UTF-8 используют чаще?**
1. **Экономия места**: Для английского текста UTF-8 в 2 раза компактнее UTF-16.  
   Например:  
   - Текст `Hello World` → **11 байт** в UTF-8 vs **22 байта** в UTF-16.  
   - Веб-страницы и JSON-данные с преимущественно латиницей будут «весить» меньше.

2. **Совместимость с ASCII**: Большинство старых систем и протоколов (например, HTTP) изначально работают с ASCII, а UTF-8 — его прямое расширение.

3. **Нет проблем с порядком байтов**: UTF-8 не требует BOM, что упрощает обработку данных.  
   В UTF-16 нужно учитывать, в каком порядке идут байты (little-endian или big-endian).

4. **Универсальность**: UTF-8 поддерживает все символы Unicode, как и UTF-16, но без избыточности для западных языков.

5. **Стандарт для веба**: HTML, XML, JSON рекомендуют использовать UTF-8.  
   Например, тег `<meta charset="UTF-8">` в HTML.

---

### **Когда используют UTF-16?**
- **Windows**: Внутренняя кодировка для строк в WinAPI.
- **Java и .NET**: Некоторые API по умолчанию работают с UTF-16.
- **Тексты с иероглифами**: Если 90% символов — китайские/японские, UTF-16 может быть немного эффективнее (но часто выигрыш незначителен).

---

### **Главный вывод**
UTF-8 — это «золотая середина»:  
- ✅ **Малый размер** для латиницы,  
- ✅ **Поддержка всех языков**,  
- ✅ **Совместимость** со старыми системами.  

Поэтому его выбирают для веба, баз данных, файлов и кросс-платформенных приложений.  
UTF-16 же остаётся в нишевых случаях (например, внутри Windows).

## 2.3 Subword Tokenization
While byte-level tokenization can alleviate the out-of-vocabulary issues faced by word-level tokenizers, tok-
enizing text into bytes results in extremely long input sequences. This slows down model training, since a sentence with 10 words might only be 10 tokens long in a word-level language model, but could be 50 or
more tokens long in a character-level model (depending on the length of the words). Processing these longer
sequences requires more computation at each step of the model. Furthermore, language modeling on byte
sequences is diﬀicult because the longer input sequences create long-term dependencies in the data.